{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dino Diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/madebyollin/dino-diffusion/blob/main/Dino_Diffusion.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXzEyXx-36QU"
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GtJSiiuF382r"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "import random\n",
    "from collections import namedtuple\n",
    "from pathlib import Path\n",
    "from functools import lru_cache\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "th.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W5maBpmc5OPM"
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    device = \"cuda\" if th.cuda.is_available() else \"cpu\"\n",
    "    channels = 3\n",
    "    hw = 64\n",
    "    shape = (channels, hw, hw)\n",
    "    dataset = \"pokemon\"\n",
    "\n",
    "def show(x):\n",
    "    if not isinstance(x, th.Tensor) or x.ndim == 4:\n",
    "        x = th.cat(tuple(x), -1)\n",
    "    display(TF.to_pil_image(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBGvX8e7Rak4"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cDFVcHrMSS30",
    "outputId": "e810526e-9511-45b0-92e9-f7ebea3c0096"
   },
   "outputs": [],
   "source": [
    "def get_dataset(name):\n",
    "    if Path(name).exists():\n",
    "        print(f\"dataset '{name}' already exists; skipping...\")\n",
    "        return\n",
    "    !git clone https://huggingface.co/datasets/huggan/{name} && (cd {name} && git lfs pull)\n",
    "    import pyarrow.parquet as pq\n",
    "    from io import BytesIO\n",
    "\n",
    "    i = 0\n",
    "    for table in Path(f\"{name}/data\").glob(\"*.parquet\"):\n",
    "        for row in tqdm(pq.read_table(table)[0]):\n",
    "            Image.open(BytesIO(row[\"bytes\"].as_py())).save(f\"{name}/{i:04d}.jpg\")\n",
    "            i += 1\n",
    "get_dataset(Config.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rgQfFMNY32yd"
   },
   "outputs": [],
   "source": [
    "Sample = namedtuple(\"Sample\", (\"im\", \"noisy_im\", \"noise_level\"))\n",
    "\n",
    "def alpha_blend(a, b, alpha):\n",
    "    return alpha * a + (1 - alpha) * b\n",
    "\n",
    "@lru_cache(maxsize=10000)\n",
    "def load_im(path):\n",
    "    return TF.pil_to_tensor(TF.center_crop(TF.resize(Image.open(path), Config.hw), Config.hw).convert(\"RGB\"))\n",
    "\n",
    "class Dataset(th.utils.data.Dataset):\n",
    "    def __init__(self, p):\n",
    "        self.ims = list(Path(p).rglob(\"*.jpg\")) + list(Path(p).rglob(\"*.png\"))\n",
    "    def __len__(self):\n",
    "        return len(self.ims)\n",
    "    def __getitem__(self, i):\n",
    "        im = load_im(self.ims[i]) / 255.0\n",
    "        if random.random() < 0.5:\n",
    "            im = TF.hflip(im)\n",
    "        noise = th.rand_like(im)\n",
    "        noise_level = th.rand(1, 1, 1)\n",
    "        noisy_im = alpha_blend(noise, im, noise_level)\n",
    "        return Sample(im, noisy_im, noise_level)\n",
    "\n",
    "d_train = Dataset(Config.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "id": "CJ6QsO5YAY_S",
    "outputId": "074c3bda-c675-4c80-df6e-0cb32797f8b9"
   },
   "outputs": [],
   "source": [
    "def demo_dataset(dataset, n=16):\n",
    "    print(f\"Dataset has {len(dataset)} samples (not counting augmentation).\")\n",
    "    print(f\"Here are some samples from the dataset:\")\n",
    "    samples = random.choices(dataset, k=n)\n",
    "    print(f\"Inputs\")\n",
    "    show(s.noisy_im for s in samples)\n",
    "    show(s.noise_level.expand(3, 16, Config.hw) for s in samples)\n",
    "    print(f\"Target Outputs\")\n",
    "    show(s.im for s in samples)\n",
    "demo_dataset(d_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w9ktK3jnSidk"
   },
   "outputs": [],
   "source": [
    "def to_device(ims):\n",
    "    return Sample(*(x.to(Config.device) for x in ims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BEZYoD50Rak6",
    "outputId": "7cf0a320-90f0-4ba3-da24-1b37e1b788f8"
   },
   "outputs": [],
   "source": [
    "# make sure the entire dataset loads\n",
    "for batch in tqdm(th.utils.data.DataLoader(d_train, num_workers=2, batch_size=32)): to_device(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1vprylFBpWk"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7u7MqTNaE-rV"
   },
   "outputs": [],
   "source": [
    "Prediction = namedtuple(\"Prediction\", (\"denoised\"))\n",
    "\n",
    "def conv(n_in, n_out, **kwargs):\n",
    "    return nn.Conv2d(n_in, n_out, 3, padding=1, **kwargs)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(conv(n_in, n_out), nn.ReLU(), conv(n_out, n_out, bias=False))\n",
    "        self.skip = nn.Identity() if n_in == n_out else conv(n_in, n_out, bias=False)\n",
    "    def forward(self, x):\n",
    "        return self.conv(x) + self.skip(x)\n",
    "\n",
    "class Pool(nn.Module):\n",
    "    def __init__(self, n_in):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(nn.AdaptiveMaxPool2d(1), nn.Conv2d(n_in, n_in * 4, 1), nn.ReLU(), nn.Conv2d(n_in * 4, n_in, 1, bias=False))\n",
    "    def forward(self, x):\n",
    "        return self.conv(x) + x\n",
    "\n",
    "def Blocks(n_in, n_out, n_b):\n",
    "    return nn.Sequential(conv(n_in, n_out, bias=False), *[Block(n_out, n_out) for _ in range(n_b)], Pool(n_out))\n",
    "\n",
    "def Enc(n_in, n_out, n_b):\n",
    "    return nn.Sequential(nn.AvgPool2d(2), Blocks(n_in, n_out, n_b))\n",
    "\n",
    "def Dec(n_in, n_out, n_b):\n",
    "    return nn.Sequential(Blocks(n_in, n_out, n_b), nn.Upsample(scale_factor=2))\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_io=Config.channels, n_f=(64, 64, 64, 64, 64), n_b=(2, 2, 2, 2, 2)):\n",
    "        super().__init__()\n",
    "        self.cat = Blocks(n_io + 1, n_f[0], n_b[0])\n",
    "        self.enc = nn.ModuleList([Enc(n_f[i], n_f[i+1], n_b[i+1]) for i in range(len(n_f) - 1)])\n",
    "        self.dec = nn.ModuleList([Dec(n_f[i+1], n_f[i], n_b[i+1]) for i in range(len(n_f) - 1)])\n",
    "        self.out = nn.Sequential(Blocks(n_f[0], n_f[0], n_b[0]), conv(n_f[0], n_f[0]), nn.ReLU(), conv(n_f[0], n_io))\n",
    "        nn.init.constant_(self.out[-1].bias, 0.5)\n",
    "    def forward(self, x, noise_level):\n",
    "        skips = []\n",
    "        x = self.cat(th.cat([x, noise_level.expand(x[:, :1].shape)], 1))\n",
    "        for enc in self.enc:\n",
    "            skips.append(x)\n",
    "            x = enc(x)\n",
    "        for dec in reversed(self.dec):\n",
    "            x = dec(x) + skips.pop()\n",
    "        return Prediction(self.out(x))\n",
    "\n",
    "model = UNet().to(Config.device)\n",
    "\n",
    "def weight_average(w_prev, w_new, n):\n",
    "    alpha = min(0.95, n / 10)\n",
    "    return alpha_blend(w_prev, w_new, alpha)\n",
    "avg_model = th.optim.swa_utils.AveragedModel(model, avg_fn=weight_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "id": "U1qPL17fOOy4",
    "outputId": "da7576bf-eae5-4e5d-f7f1-f27aa6f90c27"
   },
   "outputs": [],
   "source": [
    "@th.no_grad()\n",
    "def demo_model(model, n=16):\n",
    "    model.eval()\n",
    "    n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Model has {n_parameters / 1e6:.1f} million trainable parameters.\")\n",
    "    x = th.rand(n, *Config.shape, device=Config.device)\n",
    "    noise_level = th.rand(n, 1, 1, 1, device=Config.device)\n",
    "    y = model(x, noise_level)\n",
    "    print(f\"Here are some model outputs on random noise:\")\n",
    "    show(y.denoised.clamp(0, 1))\n",
    "    model.train()\n",
    "demo_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Utzy-yt8kWOr"
   },
   "source": [
    "## Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4HAjLpaqkPs9"
   },
   "outputs": [],
   "source": [
    "@th.no_grad()\n",
    "def generate_images(model, n_images=16, n_steps=100, step_size=2.0):\n",
    "    model.eval()\n",
    "    x, prev = th.rand(n_images, *Config.shape, device=Config.device), None\n",
    "    noise_levels = th.linspace(1, 0, n_steps + 1, device=Config.device)\n",
    "    for nl_in, nl_out in zip(noise_levels, noise_levels[1:]):\n",
    "        denoised = pred = model(x, nl_in.view(1, 1, 1, 1)).denoised\n",
    "        if prev is not None: denoised = prev + step_size * (denoised - prev)\n",
    "        x, prev = alpha_blend(x, denoised, nl_out / nl_in), pred\n",
    "    model.train()\n",
    "    return x.clamp(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98
    },
    "id": "6cGKrZLlcwXG",
    "outputId": "71bce7a0-1ce6-4968-beb9-e8f2275b43f9"
   },
   "outputs": [],
   "source": [
    "def demo_image_generation(model):\n",
    "    print(\"Here are some generated images (for an untrained model, they will be blank gray squares)\")\n",
    "    show(generate_images(avg_model, n_images=16))\n",
    "demo_image_generation(avg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zz_1RFozi-bs"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tUkKew44Rak-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class Visualizer:\n",
    "    def __init__(self):\n",
    "        self.smoothed_loss = None\n",
    "        self.losses_since_last_vis = []\n",
    "        self.avg_losses = []\n",
    "        self.steps = []\n",
    "        self.step = 0\n",
    "        self.t_last_vis = 0\n",
    "        self.t_last_save = 0\n",
    "        self.t_start = None\n",
    "        folder, idx = datetime.datetime.now().strftime(\"%Y_%m_%d\") + \"_training_logs\", 0\n",
    "        while Path(f\"{folder}_{idx}\").exists():\n",
    "            idx += 1\n",
    "        self.folder = Path(f\"{folder}_{idx}\")\n",
    "        self.folder.mkdir()\n",
    "    def __call__(self, model, t, x, y, loss, n_demo=16):\n",
    "        self.losses_since_last_vis.append(loss)\n",
    "        self.smoothed_loss = loss if self.smoothed_loss is None else 0.99 * self.smoothed_loss + 0.01 * loss\n",
    "        self.step += 1\n",
    "        if self.t_start is None:\n",
    "            self.t_start = t\n",
    "        if t > self.t_last_vis + 30:\n",
    "            generated_images = generate_images(model, n_images=n_demo)\n",
    "            clear_output(wait=True)\n",
    "            print(\"Input Noisified Image, Noise Level\")\n",
    "            show(x.noisy_im[:n_demo])\n",
    "            show(x.noise_level.expand(len(x.noise_level), 3, 16, Config.hw)[:n_demo])\n",
    "            print(\"Predictions\")\n",
    "            show(y.denoised[:n_demo].clamp(0, 1))\n",
    "            print(\"Targets\")\n",
    "            show(x.im[:n_demo])\n",
    "            self.steps.append(self.step)\n",
    "            self.avg_losses.append(sum(self.losses_since_last_vis) / len(self.losses_since_last_vis))\n",
    "            self.losses_since_last_vis = []\n",
    "            print(\"Generated Images (Averaged Model)\")\n",
    "            show(generated_images)\n",
    "            plt.title(\"Losses\")\n",
    "            plt.plot(self.steps, self.avg_losses)\n",
    "            plt.gcf().set_size_inches(16, 4)\n",
    "            plt.ylim(0, 1.5 * self.avg_losses[-1])\n",
    "            if t > self.t_last_save + 120:\n",
    "                th.save(model.state_dict(), self.folder / \"model.pth\")\n",
    "                th.save((self.steps, self.avg_losses), self.folder / \"stats.pth\")\n",
    "                TF.to_pil_image(th.cat(tuple(generated_images), -1)).save(self.folder / f\"generated_{self.step:07d}.jpg\", quality=95)\n",
    "                plt.gcf().savefig(self.folder / \"stats.jpg\")\n",
    "                self.t_last_save = t\n",
    "            plt.show()\n",
    "            self.t_last_vis = t\n",
    "        print(\n",
    "            f\"\\r{self.step: 5d} Steps; {int(t - self.t_start): 3d} Seconds; \"\n",
    "            f\"{60 * self.step / (t - self.t_start + 1):.1f} Steps / Min; \"\n",
    "            f\"{len(x.im) * 60 * self.step / (t - self.t_start + 1):.1f} Images / Min; \"\n",
    "            f\"Smoothed Loss {self.smoothed_loss:.5f}; \"\n",
    "        , end=\"\")\n",
    "        \n",
    "class Looper(th.utils.data.Dataset):\n",
    "    def __init__(self, dataset, n=1<<20):\n",
    "        self.dataset = dataset\n",
    "        self.n = n\n",
    "    def __len__(self):\n",
    "        return max(len(self.dataset), self.n)\n",
    "    def __getitem__(self, i):\n",
    "        return self.dataset[i % len(self.dataset)]\n",
    "        \n",
    "class Trainer:\n",
    "    def __init__(self, model, avg_model, dataset, batch_size=16):\n",
    "        self.model = model\n",
    "        self.avg_model = avg_model\n",
    "        self.last_avg_time = time.time()\n",
    "        self.opt = th.optim.AdamW(model.parameters(), 3e-4, amsgrad=True)\n",
    "        num_workers = min(8, len(os.sched_getaffinity(0)) if hasattr(os, \"sched_getaffinity\") else os.cpu_count())\n",
    "        self.dataloader = th.utils.data.DataLoader(Looper(dataset), batch_size=batch_size, shuffle=True, drop_last=True, num_workers=num_workers)\n",
    "        self.dl_iter = iter(self.dataloader)\n",
    "        self.visualizer = Visualizer()\n",
    "\n",
    "    def avg_model_step(self, t):\n",
    "        if t > self.last_avg_time + 2:\n",
    "            self.avg_model.update_parameters(self.model)\n",
    "            self.last_avg_time = t\n",
    "\n",
    "    def get_batch(self):\n",
    "        try:\n",
    "            batch = next(self.dl_iter)\n",
    "        except StopIteration:\n",
    "            self.dl_iter = iter(self.dataloader)\n",
    "            batch = next(self.dl_iter)\n",
    "        return to_device(batch)\n",
    "\n",
    "    def train(self, n_seconds):\n",
    "        self.model.train()\n",
    "        start_time = time.time()\n",
    "        while time.time() < start_time + n_seconds:\n",
    "            self.train_step(time.time())\n",
    "\n",
    "    def train_step(self, t):\n",
    "        x = self.get_batch()\n",
    "        y = self.model(x.noisy_im, x.noise_level)\n",
    "        loss = F.mse_loss(y.denoised, x.im)\n",
    "        self.opt.zero_grad(); loss.backward(); self.opt.step(); self.avg_model_step(t)\n",
    "        self.visualizer(self.avg_model, t, x, y, loss.item())\n",
    "\n",
    "trainer = Trainer(model, avg_model, d_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "id": "S7e8S2mPRak-",
    "outputId": "57a41be4-6547-43c6-d177-d8080f1f287a"
   },
   "outputs": [],
   "source": [
    "trainer.train(n_seconds=60*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N4ijxnzkRak_"
   },
   "outputs": [],
   "source": [
    "def demo_sample_grids(dataset, model, rows=8, cols=8):\n",
    "    real_rows, fake_rows = [], []\n",
    "    for i in tqdm(range(rows)):\n",
    "        real_rows.append(th.cat([random.choice(dataset).im for _ in range(cols)], -1))\n",
    "        fake_rows.append(th.cat(tuple(generate_images(model, n_images=cols)), -1))\n",
    "    real_im = th.cat(real_rows, -2)\n",
    "    padding = th.ones_like(real_im[..., :32])\n",
    "    fake_im = th.cat(fake_rows, -2).cpu()\n",
    "    return TF.to_pil_image(th.cat([real_im, padding, fake_im], -1))\n",
    "demo_sample_grids(d_train, avg_model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
